{"ts": 1764205112.566297, "event": "start", "wiki_in": "/opt/app/wiki_dump", "out": "/opt/app/workspace/store/wiki", "max_pages": null}
{"ts": 1764205268.2670758, "event": "error", "message": "An error occurred while calling o352.csv"}
{"ts": 1764241842.2582836, "event": "start", "wiki_in": "/opt/app/wiki_dump", "out": "/opt/app/workspace/store/wiki", "max_pages": 100}
{"ts": 1764241853.2145624, "event": "error", "message": "An error occurred while calling o369.csv"}
{"ts": 1764241991.9640572, "event": "start", "wiki_in": "/opt/app/wiki_dump", "out": "/opt/app/workspace/store/wiki", "max_pages": 100}
{"ts": 1764242984.9919045, "event": "start", "wiki_in": "/opt/app/wiki_dump", "out": "/opt/app/workspace/store/wiki", "max_pages": 1000}
{"ts": 1764243574.1239414, "event": "error", "message": "An error occurred while calling o156.count.\n: org.apache.spark.SparkException: Job 3 cancelled because SparkContext was shut down\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$cleanUpAfterSchedulerStop$1(DAGScheduler.scala:1212)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$cleanUpAfterSchedulerStop$1$adapted(DAGScheduler.scala:1210)\n\tat scala.collection.mutable.HashSet.foreach(HashSet.scala:79)\n\tat org.apache.spark.scheduler.DAGScheduler.cleanUpAfterSchedulerStop(DAGScheduler.scala:1210)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onStop(DAGScheduler.scala:3011)\n\tat org.apache.spark.util.EventLoop.stop(EventLoop.scala:84)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$stop$3(DAGScheduler.scala:2902)\n\tat org.apache.spark.util.Utils$.tryLogNonFatalError(Utils.scala:1509)\n\tat org.apache.spark.scheduler.DAGScheduler.stop(DAGScheduler.scala:2902)\n\tat org.apache.spark.SparkContext.$anonfun$stop$12(SparkContext.scala:2128)\n\tat org.apache.spark.util.Utils$.tryLogNonFatalError(Utils.scala:1509)\n\tat org.apache.spark.SparkContext.stop(SparkContext.scala:2128)\n\tat org.apache.spark.SparkContext.stop(SparkContext.scala:2081)\n\tat org.apache.spark.SparkContext.$anonfun$new$31(SparkContext.scala:664)\n\tat org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:214)\n\tat org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$2(ShutdownHookManager.scala:188)\n\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n\tat org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$1(ShutdownHookManager.scala:188)\n\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n\tat scala.util.Try$.apply(Try.scala:213)\n\tat org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)\n\tat org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)\n\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Unknown Source)\n\tat java.base/java.util.concurrent.FutureTask.run(Unknown Source)\n\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)\n\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)\n\tat java.base/java.lang.Thread.run(Unknown Source)\n"}
{"ts": 1764243724.7421446, "event": "start", "wiki_in": "/opt/app/wiki_dump", "out": "/opt/app/workspace/store/wiki", "max_pages": 1000}
{"ts": 1764244058.4747233, "event": "start", "wiki_in": "/opt/app/wiki_dump", "out": "/opt/app/workspace/store/wiki", "max_pages": 1000}
